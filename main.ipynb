{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 10:26:20.174 No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import urllib3\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from meteostat import Point, Hourly, Daily, units\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "##### STRAVA API DATA EXTRACTION ####\n",
    "# Disable SSL warnings\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "auth_url = 'https://www.strava.com/oauth/token'\n",
    "\n",
    "payload = {\n",
    "    'client_id': f'{st.secrets['client_id']}',\n",
    "    'client_secret': f'{st.secrets['client_secret']}',\n",
    "    'refresh_token': f'{st.secrets['refresh_token']}',\n",
    "    'grant_type': 'refresh_token',\n",
    "    'f': 'json'\n",
    "}\n",
    "\n",
    "res = requests.post(auth_url, data=payload, verify=False)\n",
    "access_token = res.json()['access_token']\n",
    "\n",
    "header = {'Authorization': 'Bearer ' + access_token}\n",
    "\n",
    "def get_strava_data() -> pd.DataFrame:\n",
    "    '''This function builds the dataframe from Strava API data. It is used to then cache the dataframe for faster loading in the Streamlit app.\n",
    "    \n",
    "    Returns:\n",
    "        pre_df (DataFrame): DataFrame of activities and gear data'''\n",
    "        \n",
    "    # Strava API only allows 200 results per page. This function loops through until all results are collected\n",
    "    def get_activities_data() -> pd.DataFrame:\n",
    "        '''This function gets all activities data from Strava API\n",
    "        \n",
    "        Returns:\n",
    "            data (DataFrame): Normalized JSON data of activities'''\n",
    "            \n",
    "        # set the URL for the Strava API\n",
    "        activities_url = 'https://www.strava.com/api/v3/athlete/activities'\n",
    "        # set value of page to start at page 1\n",
    "        page = 1\n",
    "        # create an empty list to store all data\n",
    "        data = []\n",
    "        # set new_results to True to start the loop\n",
    "        new_results = True\n",
    "        \n",
    "        while new_results:\n",
    "            # requests one page at a time (200 results)\n",
    "            get_activities = requests.get(activities_url, headers=header, params={'per_page': 200, 'page': page}).json()\n",
    "            # feedback\n",
    "            print(f\"Fetching page {page}\")\n",
    "            print(f\"Number of activities fetched: {len(get_activities)}\")\n",
    "            # if there are no results, the loop will stop\n",
    "            new_results = get_activities\n",
    "            # add the results to the data list\n",
    "            data.extend(get_activities)\n",
    "            # increment the page number\n",
    "            page += 1\n",
    "\n",
    "            if page > 20:\n",
    "                print('Stopping after 20 pages to avoid excessive API calls')\n",
    "                break\n",
    "            \n",
    "        return pd.json_normalize(data)\n",
    "            \n",
    "    # get all activities data\n",
    "    activities = get_activities_data()\n",
    "    \n",
    "    # convert meters to miles\n",
    "    activities.distance = (activities.distance / 1609.34).round(2)\n",
    "    # convert to mph\n",
    "    activities.average_speed = (activities.average_speed * 2.23694).round(2)\n",
    "    activities.max_speed = (activities.max_speed * 2.23694).round(2)\n",
    "    # convert to feet\n",
    "    activities.total_elevation_gain = (activities.total_elevation_gain * 3.28084).round(2)\n",
    "    activities.elev_high = (activities.elev_high * 3.28084).round(2)\n",
    "    activities.elev_low = (activities.elev_low * 3.28084).round(2)\n",
    "\n",
    "    activities_df = pd.DataFrame(activities)\n",
    "    \n",
    "    def add_weather_data(df: pd.DataFrame, max_workers=20) -> pd.DataFrame:\n",
    "        '''This function gets weather data from Meteostat and adds it onto the activities DataFrame\n",
    "        \n",
    "        Args:\n",
    "            df (DataFrame): Activities data frame that uses latitude, longitude, and timestamps to get weather data\n",
    "            max_worker (int): Number of threads to use in the multi-threading process\n",
    "            \n",
    "        Returns:\n",
    "            df (DataFrame): Original df with weatehr data appended'''\n",
    "            \n",
    "        def get_weather(row):\n",
    "            '''This function takes the latitude, longitude, and timestamp for each row and calls the Meteostat API for data\n",
    "            \n",
    "            Args:\n",
    "                row: The row in the DataFrame used in the parent function\n",
    "                \n",
    "            Returns:\n",
    "                weather_data (dict): The temperature and relative humidity of the row's activity as a dictionary'''\n",
    "            \n",
    "            # get the location of the activity\n",
    "            location = Point(row['start_latitude'], row['start_longitude'])\n",
    "            # get the time of the activity\n",
    "            timestamp = pd.to_datetime(row['start_date_local'])\n",
    "            # only use the hour it started\n",
    "            start = end = timestamp.replace(tzinfo=None, minute=0, second=0, microsecond=0)\n",
    "\n",
    "            # call meteostat API\n",
    "            try:\n",
    "                data = Hourly(location, start, end)\n",
    "                data = data.convert(units.imperial).fetch()\n",
    "                if not data.empty:\n",
    "                    # only get the first row of data\n",
    "                    weather = data[['temp', 'rhum']].iloc[0]\n",
    "                    return {'temp': weather['temp'], 'rhum': weather['rhum']}\n",
    "                else:\n",
    "                    return {'temp': None, 'rhum': None}\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching weather for {timestamp}: {e}\")\n",
    "                return {'temp': None, 'rhum': None}\n",
    "            \n",
    "        # separate the latitude and longitude from the activity data\n",
    "        df[['start_latitude', 'start_longitude']] = pd.DataFrame(df['start_latlng'].tolist(), index=df.index)\n",
    "\n",
    "        # multi-threading so the function can call the API and iterate through rows faster\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            weather_data = list(executor.map(get_weather, [row for _, row in df.iterrows()]))\n",
    "\n",
    "        # get the weatehr data and concat the two DataFrames\n",
    "        weather_df = pd.DataFrame(weather_data)\n",
    "        return pd.concat([df.reset_index(drop=True), weather_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    activities_df = add_weather_data(activities_df)\n",
    "\n",
    "    # get distinct gear id's\n",
    "    gear_id_list = activities_df['gear_id'].unique()\n",
    "    gear_id_list = gear_id_list[~pd.isnull(gear_id_list)]\n",
    "\n",
    "    def get_gear_data(gear_list: list) -> pd.DataFrame:\n",
    "        '''This function gets gear data from Strava API\n",
    "        \n",
    "        Args:\n",
    "            gear_list (array): List of distinct gear ids\n",
    "            \n",
    "            Returns:\n",
    "                data (DataFrame): Normalized JSON data of gear'''\n",
    "        # set the URL for the Strava API\n",
    "        gear_url = 'https://www.strava.com/api/v3/gear/{id}'\n",
    "        # create empty list to store gear data\n",
    "        data = []\n",
    "        # loop through gear_list and get gear data\n",
    "        for gear_id in gear_list:\n",
    "            get_gear = requests.get(gear_url.format(id=gear_id), headers=header).json()\n",
    "            data.append(get_gear)\n",
    "        return pd.json_normalize(data)\n",
    "    \n",
    "    # get all gear data\n",
    "    gear = get_gear_data(gear_id_list)\n",
    "\n",
    "    # convert meters to miles\n",
    "    gear.distance = gear.distance / 1609.34\n",
    "\n",
    "    gear = gear.drop(columns=['converted_distance'])\n",
    "\n",
    "    ##### DATA CLEANING AND TRANSFORMATION #####\n",
    "    # create base dataframe joining activity and gear data\n",
    "    pre_df = pd.merge(activities_df,\n",
    "                    gear, \n",
    "                    how='left',\n",
    "                    left_on='gear_id',\n",
    "                    right_on='id',\n",
    "                    suffixes=('_activity', '_gear')).drop(columns='id_gear')\n",
    "\n",
    "    # convert moving_time and elapsed time to H% M% S% format\n",
    "    pre_df['moving_time'] = pd.to_timedelta(pd.to_datetime(pre_df['moving_time'], unit='s').dt.strftime('%H:%M:%S'))\n",
    "    pre_df['elapsed_time'] = pd.to_timedelta(pd.to_datetime(pre_df['elapsed_time'], unit='s').dt.strftime('%H:%M:%S'))\n",
    "\n",
    "    # convert start_date and start_date_local to datetime\n",
    "    pre_df['start_date'] = pd.to_datetime(pd.to_datetime(pre_df['start_date']).dt.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    pre_df['start_date_local'] = pd.to_datetime(pd.to_datetime(pre_df['start_date_local']).dt.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "    # add start time for analysis and in am/pm format\n",
    "    pre_df['start_time_local_24h'] = pd.to_datetime(pre_df['start_date_local']).dt.time\n",
    "    pre_df['start_time_local_12h'] = pd.to_datetime(pre_df['start_date_local']).dt.strftime(\"%I:%M %p\")\n",
    "\n",
    "    # add day of week\n",
    "    pre_df['day_of_week'] = pd.to_datetime(pre_df['start_date_local']).dt.day_name()\n",
    "\n",
    "    # add month\n",
    "    pre_df['month'] = pd.to_datetime(pre_df['start_date_local']).dt.month_name()\n",
    "\n",
    "    # add month year\n",
    "    pre_df['month_year'] = pd.to_datetime(pd.to_datetime(pre_df['start_date_local']).dt.strftime('%Y-%m'))\n",
    "    \n",
    "    # add month year name\n",
    "    pre_df['month_year_name'] = pd.to_datetime(pre_df['start_date_local']).dt.strftime('%b %Y')\n",
    "\n",
    "    # add year label\n",
    "    pre_df['year'] = pd.to_datetime(pre_df['start_date_local']).dt.year\n",
    "    \n",
    "    pre_df.drop(columns=['start_latlng', 'end_latlng', 'start_latitude', 'start_longitude'], inplace=True)\n",
    "        \n",
    "    return pre_df\n",
    "\n",
    "@st.cache_data()\n",
    "def load_data() -> pd.DataFrame:\n",
    "    \n",
    "    '''This function loads the dataframe from the session state. It then corrects the data types.\n",
    "    \n",
    "    Returns: DataFrame: Strave dataframe'''\n",
    "    \n",
    "    df = pd.DataFrame(st.session_state.strava_data)\n",
    "    \n",
    "    # convert moving_time and elapsed time to H% M% S% format\n",
    "    df['moving_time'] = pd.to_timedelta(df['moving_time'])\n",
    "    df['elapsed_time'] = pd.to_timedelta(df['elapsed_time'])\n",
    "    \n",
    "    # convert start_date and start_date_local to datetime\n",
    "    df['start_date'] = pd.to_datetime(pd.to_datetime(df['start_date']).dt.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    df['start_date_local'] = pd.to_datetime(pd.to_datetime(df['start_date_local']).dt.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    \n",
    "    # add start time for analysis and in am/pm format\n",
    "    df['start_time_local_24h'] = pd.to_datetime(df['start_date_local']).dt.time\n",
    "    df['start_time_local_12h'] = pd.to_datetime(df['start_date_local']).dt.strftime(\"%I:%M %p\")\n",
    "\n",
    "    # add month year\n",
    "    df['month_year'] = pd.to_datetime(pd.to_datetime(df['start_date_local']).dt.strftime('%Y-%m'))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def default_activity_selection(highlighted_activities: list) -> list:\n",
    "    \n",
    "    '''This function sets the default activity type selection for the filter and captures the selection to use across the app.\n",
    "    \n",
    "    Args:\n",
    "        highlighted_activities (list): List of highlighted activities\n",
    "        \n",
    "    Returns:\n",
    "        act_filter (list): List of selected activities'''\n",
    "    \n",
    "    if 'act_type_selection' not in st.session_state:\n",
    "        act_filter = highlighted_activities\n",
    "    else:\n",
    "        act_filter = st.session_state.act_type_selection\n",
    "    \n",
    "    return act_filter\n",
    "\n",
    "def default_year_selection() -> str:\n",
    "    \n",
    "    '''This function sets the default year selection for the filter and captures the selection to use across the app.'''\n",
    "    \n",
    "    if 'year_selection' not in st.session_state:\n",
    "        year_filter_1 = 'Rolling 12 Months'\n",
    "    else:\n",
    "        year_filter_1 = st.session_state.year_selection\n",
    "    \n",
    "    return year_filter_1\n",
    "\n",
    "def default_gear_brand_selection(gear_brand_list: list) -> list:\n",
    "    \n",
    "    '''This function sets the default gear brand selection for the filter and captures the selection to use across the app.\n",
    "    \n",
    "    Args:\n",
    "        gear_brand_list (list): List of gear brands\n",
    "        \n",
    "    Returns:\n",
    "        gear_filter (list): List of selected gear brands'''\n",
    "    \n",
    "    if 'gear_brand_selection' not in st.session_state:\n",
    "        gear_filter = gear_brand_list\n",
    "    else:\n",
    "        gear_filter = st.session_state.gear_brand_selection\n",
    "    \n",
    "    return gear_filter\n",
    "\n",
    "def df_query_builder(df: pd.DataFrame, year_selection: str, local_vars: dict) -> pd.DataFrame:\n",
    "    '''This function builds a query to filter the dataframe based on the selected activity type, year and gear brand.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): DataFrame to filter\n",
    "        year_selection (str): Selected year from filter\n",
    "        local_vars (dict): Local variables to use in the query\n",
    "        \n",
    "    Returns:\n",
    "        df (DataFrame): Filtered dataframe based on the selected filters'''\n",
    "        \n",
    "    conditions = []\n",
    "    \n",
    "    # activity type filter\n",
    "    conditions.append(\"type in @act_type_selection\")\n",
    "\n",
    "    # year filter\n",
    "    if year_selection == 'All':\n",
    "        conditions.append(\"year != 'None'\")\n",
    "    elif year_selection == 'Rolling 12 Months':\n",
    "        conditions.append(\"start_date_local >= @rolling_12_months\")\n",
    "    else:\n",
    "        conditions.append(\"year == @year_selection\")\n",
    "        \n",
    "    # gear brand filter\n",
    "    conditions.append(\"brand_name in @gear_brand_selection\")\n",
    "\n",
    "    query = ' and '.join(conditions)\n",
    "    \n",
    "    return df.query(query, local_dict=local_vars)\n",
    "\n",
    "def convert_timedelta(td: pd.Timedelta) -> str:\n",
    "    '''This function converts a timedelta object to a string in hours and minutes\n",
    "    \n",
    "    Args:\n",
    "        td (timedelta): timedelta object\n",
    "        \n",
    "    Returns:\n",
    "        str: string in hours and minutes\n",
    "    '''\n",
    "    total_seconds = int(td.total_seconds())\n",
    "    hours, remainder = divmod(total_seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return f\"{hours} hrs {minutes} min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page 1\n",
      "Number of activities fetched: 200\n",
      "Fetching page 2\n",
      "Number of activities fetched: 200\n",
      "Fetching page 3\n",
      "Number of activities fetched: 200\n",
      "Fetching page 4\n",
      "Number of activities fetched: 22\n",
      "Fetching page 5\n",
      "Number of activities fetched: 0\n"
     ]
    }
   ],
   "source": [
    "df = get_strava_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page 1\n",
      "Number of activities fetched: 200\n",
      "Fetching page 2\n",
      "Number of activities fetched: 200\n",
      "Fetching page 3\n",
      "Number of activities fetched: 200\n",
      "Fetching page 4\n",
      "Number of activities fetched: 22\n",
      "Fetching page 5\n",
      "Number of activities fetched: 0\n"
     ]
    }
   ],
   "source": [
    "def get_activities_data() -> pd.DataFrame:\n",
    "    '''This function gets all activities data from Strava API\n",
    "    \n",
    "    Returns:\n",
    "        data (DataFrame): Normalized JSON data of activities'''\n",
    "        \n",
    "    # set the URL for the Strava API\n",
    "    activities_url = 'https://www.strava.com/api/v3/athlete/activities'\n",
    "    # set value of page to start at page 1\n",
    "    page = 1\n",
    "    # create an empty list to store all data\n",
    "    data = []\n",
    "    # set new_results to True to start the loop\n",
    "    new_results = True\n",
    "    \n",
    "    while new_results:\n",
    "        # requests one page at a time (200 results)\n",
    "        get_activities = requests.get(activities_url, headers=header, params={'per_page': 200, 'page': page}).json()\n",
    "        # feedback\n",
    "        print(f\"Fetching page {page}\")\n",
    "        print(f\"Number of activities fetched: {len(get_activities)}\")\n",
    "        # if there are no results, the loop will stop\n",
    "        new_results = get_activities\n",
    "        # add the results to the data list\n",
    "        data.extend(get_activities)\n",
    "        # increment the page number\n",
    "        page += 1\n",
    "\n",
    "        if page > 20:\n",
    "            print('Stopping after 20 pages to avoid excessive API calls')\n",
    "            break\n",
    "        \n",
    "    return pd.json_normalize(data)\n",
    "        \n",
    "# get all activities data\n",
    "activities = get_activities_data()\n",
    "\n",
    "# convert meters to miles\n",
    "activities.distance = (activities.distance / 1609.34).round(2)\n",
    "# convert to mph\n",
    "activities.average_speed = (activities.average_speed * 2.23694).round(2)\n",
    "activities.max_speed = (activities.max_speed * 2.23694).round(2)\n",
    "# convert to feet\n",
    "activities.total_elevation_gain = (activities.total_elevation_gain * 3.28084).round(2)\n",
    "activities.elev_high = (activities.elev_high * 3.28084).round(2)\n",
    "activities.elev_low = (activities.elev_low * 3.28084).round(2)\n",
    "\n",
    "activities_df = pd.DataFrame(activities)\n",
    "\n",
    "def add_weather_data(df: pd.DataFrame, max_workers=20) -> pd.DataFrame:\n",
    "    '''This function gets weather data from Meteostat and adds it onto the activities DataFrame\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): Activities data frame that uses latitude, longitude, and timestamps to get weather data\n",
    "        max_worker (int): Number of threads to use in the multi-threading process\n",
    "        \n",
    "    Returns:\n",
    "        df (DataFrame): Original df with weatehr data appended'''\n",
    "        \n",
    "    def get_weather(row):\n",
    "        '''This function takes the latitude, longitude, and timestamp for each row and calls the Meteostat API for data\n",
    "        \n",
    "        Args:\n",
    "            row: The row in the DataFrame used in the parent function\n",
    "            \n",
    "        Returns:\n",
    "            weather_data (dict): The temperature and relative humidity of the row's activity as a dictionary'''\n",
    "        \n",
    "        # get the location of the activity\n",
    "        location = Point(row['start_latitude'], row['start_longitude'])\n",
    "        # get the time of the activity\n",
    "        timestamp = pd.to_datetime(row['start_date_local'])\n",
    "        # only use the hour it started\n",
    "        start = end = timestamp.replace(tzinfo=None, minute=0, second=0, microsecond=0)\n",
    "\n",
    "        # call meteostat API\n",
    "        try:\n",
    "            data = Hourly(location, start, end)\n",
    "            data = data.convert(units.imperial).fetch()\n",
    "            if not data.empty:\n",
    "                weather = data[['temp', 'rhum']].iloc[0]\n",
    "                return {'temp': weather['temp'], 'rhum': weather['rhum']}\n",
    "            else:\n",
    "                # Fallback to daily data\n",
    "                start_day = end_day = pd.to_datetime(timestamp.date())\n",
    "                daily_data = Daily(location, start_day, end_day)\n",
    "                daily_data = daily_data.convert(units.imperial).fetch()\n",
    "\n",
    "                if not daily_data.empty:\n",
    "                    daily_weather = daily_data[['tavg', 'rhum']].iloc[0]\n",
    "                    return {'temp': daily_weather['tavg'], 'rhum': daily_weather['rhum']}\n",
    "                else:\n",
    "                    return {'temp': None, 'rhum': None}\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching weather for {timestamp}: {e}\")\n",
    "            return {'temp': None, 'rhum': None}\n",
    "        \n",
    "    # separate the latitude and longitude from the activity data\n",
    "    df[['start_latitude', 'start_longitude']] = pd.DataFrame(df['start_latlng'].tolist(), index=df.index)\n",
    "\n",
    "    # multi-threading so the function can call the API and iterate through rows faster\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        weather_data = list(executor.map(get_weather, [row for _, row in df.iterrows()]))\n",
    "\n",
    "    # get the weatehr data and concat the two DataFrames\n",
    "    weather_df = pd.DataFrame(weather_data)\n",
    "    return pd.concat([df.reset_index(drop=True), weather_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "activities_df = add_weather_data(activities_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = pd.to_datetime(df.loc[df['id_activity'] == 13901597211, 'start_date_local']).iloc[0]\n",
    "location = Point(40.128775, -75.524218)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2025, 3, 16)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_day = end_day = pd.to_datetime(timestamp.date())\n",
    "daily_data = Daily(location, start_day, start_day)\n",
    "daily_data = daily_data.convert(units.imperial).fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "('station', 'time')",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tavg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tmin",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tmax",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prcp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "snow",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wdir",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wspd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wpgt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pres",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tsun",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "f9880dc9-b5b3-47f4-9428-31947eb26a97",
       "rows": [],
       "shape": {
        "columns": 10,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>prcp</th>\n",
       "      <th>snow</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>wpgt</th>\n",
       "      <th>pres</th>\n",
       "      <th>tsun</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tavg, tmin, tmax, prcp, snow, wdir, wspd, wpgt, pres, tsun]\n",
       "Index: []"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
